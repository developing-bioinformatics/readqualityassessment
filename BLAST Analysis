

#figure out how to get the read length and quaity scores just for the sequences I have a BLAST hits for, and puts it all in 1 table


#suggestion: column in BLAST hits table (the queryID "query_1" "query_2") those numbers refer to back to DNA sequence in the 
#original object reads. We pulled the reads out of the DNA object and running readFastQ and passes the read object to BLAST.
#if I have a BLAST hit for query 111, look for index 111 in the widths table and put that read length as the attribute for query 111 

#this is tying together BLAST hits and read length
#create a plot that compares the read length distribution and a plot which compares the read lengths of BLAST hits


#try to incorporate LCA + BLAST code into here

library(rBLAST)
library(Biostrings)
library(taxonomizr)
library(ggplot2)
library(ShortRead)
library(dplyr)
library(stringi)
library(forcats)
library(tidyr)

#for getting fastq files:
source('https://raw.githubusercontent.com/developing-bioinformatics/eDNA_BLAST/master/R/core.R')
download_sra(sample = 'Swamp_S1_', dir.out = 'data') #this searches NCBI archive, gets all samples from the sample Swamp 1, and gets all fastq file across all amplicons and saves to a folder called "data"

#to analyze all eDNA files:
#for each file we read: a data frame (table) where one column has the SRR number, other column has all read length values
#put this code to make a table into a function

#look at read distributions here? quality scores here?

#scatter plots of relationship between E value and read quality/length 

#this code defines 

get_readlengths <- function(filename){    #this defines a function that passes in a variable called filename
  dna = readFastq(filename) 
  reads = sread(dna)
  readlengths = reads@ranges@width
  ret = cbind(rep(filename), length(readlengths))    #cbind puts the table together
  return(ret)
}


#for analyzing BLAST data:
blasthits = read.table('/projectnb/ct-shbioinf/rharbert/bioinf_notes/blasthits2.tab') #reads in BLAST hits table
dir.create("data", showWarnings = FALSE)

rapid_test = readFastq('data', pattern='rapid_test.fastq')
reads = sread(rapid_test)
widths = as.data.frame(reads@ranges@width) #this is the read lengths
qscores = quality(rapid_test) #this is quality scores

numqscores = as(qscores, "matrix") # converts to numeric scores automatically

avgscores = apply(numqscores, 1, mean, na.rm=TRUE)

avgscores = as.data.frame(avgscores) #converts from matrix to data fram
avgscores[blasthits2$id,]

widths[blasthits2$id,]

head(blasthits)
#first column: Query_1 is the first read, to access we need a vector called 1
#tell R to split that QueryID column to take off the Query_ and just have the number

blasthits %>% separate(QueryID, c('query', 'id'), "_") %>% head() #this separates QueryID column into two columns Query and ID
#we can now use the ID column as an index to do....

blasthits2=blasthits %>% separate(QueryID, c('query', 'id'), "_")
head(blasthits2)

blasthits2$qscores = avgscores[blasthits2$id,] #these create new columns in blasthits 2 for avg score and read length
blasthits2$read.length = widths[blasthits2$id,]
head(blasthits2)
sele.hits=select(blasthits2,id,species,qscores,read.length)
sele.hits

ggplot(data=blasthits2) + geom_point(aes(x=read.length, y=Alignment.Length)) #creates ggplot of read length and alignment length from blasthits2 table
#in this blasthits2 table, is there a correlation between read length and alignment length? 


#alignment length is the matching base pairs in BLAST
#E is sort of like a P value? scale that tells you what the probability of finding that match is


#creats a new column in blashits 2 called read.length and fills with values from the widths objects from the blasthits2 id column as an id o




# blasthits$readlength = reads@ranges@width[blasthits$id] #what does this too
-------
  

# Download SRA File: 11043489
srr=c('SRR11043489', 'SRR11206993', 'SRR11206994')  #figure out how to do this with just 1 file first
system(paste('fastq-dump', srr, sep=' '))

dna = readFastq(paste(srr, '.fastq',sep=''))

# parse DNA sequences
reads = sread(dna, id=id(dna))
# parse quality scores
qscores = quality(dna)

# rBLAST function for connecting to the database
bl <- blast(db="/projectnb/ct-shbioinf/blast/nt.fa") #this line says "make an object bl and assign it to this" db=database

cl <- predict(bl, reads, BLAST_args = '-num_threads 12 -evalue 1e-100')
accid = as.character(cl$SubjectID) # accession IDs of BLAST hits

# load NCBI taxonomy
#load the taxonomy database files 'nodes' and 'names'
install.packages('taxonomizr')

taxaNodes<-read.nodes.sql("/projectnb/ct-shbioinf/taxonomy/data/nodes.dmp")
## nameNode.sqlite already contains table nodes. Delete file or set overwrite=TRUE to reload
taxaNames<-read.names.sql("/projectnb/ct-shbioinf/taxonomy/data/names.dmp")

# Search the taxonomy by accession ID #

# takes accession number and gets the taxonomic ID
ids<-accessionToTaxa(accid,'/projectnb/ct-shbioinf/taxonomy/data/accessionTaxa.sql')

# displays the taxonomic names from each ID #
taxlist=getTaxonomy(ids, taxaNodes, taxaNames)

# Merge BLAST hits and taxonomy of each
cltax=cbind(cl,taxlist)

#topbygroup = blasthits %>% group_by(QueryID) %>% filter(any(Bits>350))
#dplyr code to filter based on qscore

cltop = cltax %>% 
  group_by(qscores) %>% 
  top_n(n=1, wt=Bits)

(ggplot(data=cltop) +
    geom_bar(aes(x=fct_infreq(genus))) +
    theme_minimal() +
    theme(    
      axis.text.x  = element_text(angle = 45, hjust=1)
    ) +
    xlab('')
  
)

######END

library(Biostrings)
library(taxonomizr)
library(ggplot2)
library(ShortRead)
library(dplyr)
library(stringi)
library(forcats)
library(rBLAST)
library(multidplyr)
#devtools::install_github("mhahsler/rBLAST")
# Download SRA File:
srr=c('SRR11206994')
system(paste('fastq-dump', srr, sep=' '))
# Read taxonomy database
taxaNodes<-read.nodes.sql("/projectnb/ct-shbioinf/taxonomy/data/nodes.dmp")
taxaNames<-read.names.sql("/projectnb/ct-shbioinf/taxonomy/data/names.dmp")
# read fastq
dna = readFastq('SRR11206994.fastq')
reads = sread(dna)
qscores = quality(dna) 
# plot readlength
widths = as.data.frame(reads@ranges@width)
(widthplot <- ggplot(widths) +
    geom_histogram(aes(x=reads@ranges@width), binwidth = 10) + 
    theme_linedraw() + 
    xlab('Read Length (bp)') +
    xlim(0,2000) +
    ggtitle('Read length distribution for 550bp amplicon'))
# plot qscores
numqscores = as(qscores, "matrix") # converts to numeric scores automatically
avgscores = apply(numqscores, 1, mean, na.rm=TRUE) #apply the function mean() across 
avgscores = as.data.frame(avgscores)
(ggplot(avgscores) +
    geom_histogram(aes(x=avgscores), binwidth=0.2) +
    theme_linedraw() +
    xlab('Quality Score') +
    ggtitle('Per Read Average Quality'))
## blast
bl <- blast(db="/projectnb/ct-shbioinf/blast/nt.fa")
cl <- predict(bl, reads, BLAST_args = '-num_threads 28 -evalue 1e-100')
accid = as.character(cl$SubjectID) # accession IDs of BLAST hits
# Plot results
#takes accession number and gets the taxonomic ID
ids<-accessionToTaxa(accid, '/projectnb/ct-shbioinf/taxonomy/data/accessionTaxa.sql')
#taxlist displays the taxonomic names from each ID #
taxlist=getTaxonomy(ids, taxaNodes, taxaNames)
blasthits=cbind(cl,taxlist)
cltop = blasthits %>% 
  group_by(QueryID) %>% 
  top_n(1, Bits) %>%
  filter(Perc.Ident>90) 
ggplot(cltop) + geom_density(aes(x=Alignment.Length))
(ggplot(data=cltop) +
    geom_bar(aes(x=fct_infreq(genus))) +
    theme_minimal() +
    theme(    
      axis.text.x  = element_text(angle = 45, hjust=1)
    ) +
    xlab('')
)

#Start LCA code

lca = function(x) {
  require(dplyr)
  taxnames = c('superkingdom', 'phylum', 'order', 'family', 'genus', 'species')
  shortnames = apply(x[,taxnames], 2, unique)
  countshnames = sapply(shortnames, length)
  lastuni = tail(names(countshnames[countshnames==1]), n=1)
  nombre = as.data.frame(x[1,which(colnames(x) == lastuni)])
  ret = x %>% 
    mutate(last_common = as.character(nombre[[1]])) %>%
    mutate(level_lca = lastuni)
  return(ret)
}

blasthits = read.table('blasthits2.tab')

allhits = blasthits[1:5000,] %>%
  group_by(QueryID) %>%
  group_modify(~ lca(.x)) %>%
  slice(1) %>% #keep only first row in each group (one per read)
  group_by(last_common) %>% # group by LCA taxon
  summarize(lca_count = n()) %>% # count num reads (rows) for each LCA
  arrange(desc(lca_count)) # sort descending

#plot
(lca_plot = ggplot(allhits %>% filter(!is.na(last_common)) ) +
    geom_col(aes(x=last_common, y=lca_count))) + 
  scale_y_log10() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=90))


cluster <- new_cluster(8)  #CHANGE THIS TO 2 IF YOU RUN THIS LOCALLY!!
cluster_library(cluster, 'dplyr')
cluster_copy(cluster, 'lca')

prepare = blasthits %>%
  group_by(QueryID) %>%
  partition(cluster) %>%  #split groups into cluster units
  do({lca(.)}) %>% # Use do to apply function across groups
  collect() %>% #bring it all back together
  slice(1) %>% #keep only first row in each group (one per read)
  group_by(last_common) %>% # group by LCA taxon
  summarize(lca_count = n()) %>% # count num reads (rows) for each LCA
  arrange(desc(lca_count))  %>% # sort descending
  filter(!is.na(last_common)) 
print(prepare)

(lca_plot = ggplot(prepare)  +
    geom_col(aes(x=fct_reorder(last_common, lca_count, .desc=T), y=lca_count)) + 
    scale_y_log10() +
    theme_minimal() +
    theme(axis.text.x = element_text(angle=90))
)

lca2 = function(x) {
  require(dplyr)
  taxnames = c('superkingdom', 'phylum', 'order', 'family', 'genus', 'species')
  shortnames = apply(x[,taxnames], 2, unique)
  countshnames = sapply(shortnames, length)
  numcount = countshnames==1
  lastuni = tail(names(shortnames[numcount==T]), n=1)
  nombre = as.data.frame(x[1,which(colnames(x) == lastuni)])
  newtax <- as.list(ifelse(countshnames==1,shortnames,NA))
  
  ret = x %>% 
    mutate(last_common = as.character(nombre[[1]])) %>%
    mutate(level_lca = lastuni) %>%
    mutate(superkingdom = newtax$superkingdom) %>%
    mutate(phylum = newtax$phylum) %>%
    mutate(class = newtax$class) %>%
    mutate(order = newtax$order) %>%
    mutate(family = newtax$family) %>%
    mutate(genus = newtax$genus) %>%
    mutate(species = newtax$species)
  return(ret)
}

test = blasthits[500:1000,] %>% 
  group_by(QueryID) %>%
  group_modify(~ lca2(.))

cluster <- new_cluster(8)
cluster_library(cluster, 'dplyr')
cluster_copy(cluster, 'lca2')


#split groups across multiple CPU cores
prepare = blasthits %>%
  group_by(QueryID) %>%
  partition(cluster) %>%  #split groups into cluster units
  do({lca2(.)}) %>%
  collect()


#count reads matching species:
spcount = prepare %>%
  group_by(QueryID) %>%
  slice(1) %>%
  group_by(species) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  filter(!is.na(species))


#count reads matching to genera:
gencount = prepare %>%
  group_by(QueryID) %>%
  slice(1) %>%
  group_by(genus) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  filter(!is.na(genus))

#count reads matching to families
famcount = prepare %>%
  group_by(QueryID) %>%
  slice(1) %>%
  group_by(family) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) %>%
  filter(!is.na(family))

(p1 = ggplot(gencount) +
    geom_col(aes(x=fct_reorder(genus, count, .desc=T), y=count)) + 
    scale_y_log10() +
    theme_minimal() +
    theme(axis.text.x = element_text(angle=90)) +
    xlab('Genus')
)
